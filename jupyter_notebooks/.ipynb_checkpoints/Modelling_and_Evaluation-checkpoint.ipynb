{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "871b380d-36cd-480d-8b39-280e032075da",
   "metadata": {},
   "source": [
    "# Modelling and Evaluation \n",
    "\n",
    "## Objectives\n",
    "\n",
    "The primary objective of this notebook is to achieve the Second Business Requirement, which involves the following steps:\n",
    "\n",
    "1. Engineer features for modelling.\n",
    "2. Perform data classification to distinguish between healthy Cherry leaves and those infected with powdery mildew.\n",
    "\n",
    "## Inputs\n",
    "\n",
    "The data for this project is organized as follows:\n",
    "\n",
    "1. Training data: `inputs/cherry_leaves_dataset/train` - This directory contains images of cherry leaves for training the model.\n",
    "2. Test data: `inputs/cherry_leaves_dataset/test` - This directory contains images used to evaluate the model's performance.\n",
    "3. Validation data: `inputs/cherry_leaves_dataset/validate` - This directory contains images for validating the model during training.\n",
    "4. Embedded image shapes - This refers to the dimensions of the images in the dataset.\n",
    "\n",
    "## Outputs\n",
    "\n",
    "The following outputs will be generated in this notebook:\n",
    "\n",
    "1. Images distribution plot - Plots depicting the distribution of images in the train, validation, and test sets.\n",
    "2. Image augmentation - Applying data augmentation techniques to increase the diversity of the training data and improve model generalization.\n",
    "3. Class indices for prediction inference - Changing prediction inference to human-readable labels for better understanding.\n",
    "4. Machine learning model creation and training - Building and training a model to classify cherry leaves into healthy or infected with powdery mildew.\n",
    "5. Save model - Saving the trained model for future use.\n",
    "6. Learning curve plot - Plotting the model's performance on the training and validation data over multiple epochs.\n",
    "7. Model evaluation on pickle file - Evaluating the trained model's performance and saving the evaluation results in a pickle file.\n",
    "8. Prediction on a random image file - Using the trained model to make predictions on a randomly chosen image file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafce551-d0a1-4f33-b29f-aa419ecd063f",
   "metadata": {},
   "source": [
    "## Import packages and change working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0e518e-254b-41c4-a6e5-e550f8b9a94e",
   "metadata": {},
   "source": [
    "#### Import packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aadd6a-bf3c-4f6a-aedb-49bbe6093e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.image import imread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c63ced-6c4e-43b7-b131-8fc603151238",
   "metadata": {},
   "source": [
    "#### Set working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e629dee2-46bd-45bf-b599-4a02f96079e4",
   "metadata": {},
   "source": [
    "##### Set parent of the working directory to the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81997860-7e75-40ca-b18b-a29e6a272efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = os.getcwd()\n",
    "work_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca2407b-d664-44e9-af46-aac096b30b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.dirname(work_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e558baa4-a530-44e0-9f77-ce86e302be7d",
   "metadata": {},
   "source": [
    "##### Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6faa4f2-591b-4533-a2fd-076783262e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0e56f9-374d-4d3e-aab2-1cff6e4263de",
   "metadata": {},
   "source": [
    "#### Set input directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbbdfb9-f573-4ceb-a31c-0aec8865099c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data_dir = 'inputs/cherry_leaves_dataset/cherry-leaves'\n",
    "train_path = my_data_dir + '/train'\n",
    "val_path = my_data_dir + '/validation'\n",
    "test_path = my_data_dir + '/test'\n",
    "my_data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adb888e-5751-4d26-8a99-b058fdf9f478",
   "metadata": {},
   "source": [
    "#### Set output directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70b0a6c-e406-4905-a480-673d1560c887",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 'v1'\n",
    "file_path = f'outputs/{version}'\n",
    "\n",
    "if 'outputs' in os.listdir(current_dir) and version in os.listdir(current_dir + '/outputs'):\n",
    "    print('Old version is already available create a new version.')\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(name=file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bd7a34-0ee1-4441-9fb7-eb3041798966",
   "metadata": {},
   "source": [
    "##### Set label names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cee29ec-8ece-4e52-9cec-de6ac3b90adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = os.listdir(train_path)\n",
    "print('Label for the images are', labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef74e749-bc1e-4ccb-9a25-7d00eb502289",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7cbd48-3a60-477a-9ac8-738fee08509f",
   "metadata": {},
   "source": [
    "### Set image shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7db352-a619-47ce-82f0-5277012c9e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "version = 'v1'\n",
    "image_shape = joblib.load(filename=f\"outputs/{version}/image_shape.pkl\")\n",
    "image_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897ff3ba-0360-4a19-95ea-e7789f1ae248",
   "metadata": {},
   "source": [
    "### Number of images in train, test and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e64370-5645-4ae2-80d3-83f62320b3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_freq = pd.DataFrame([]) \n",
    "for folder in ['train', 'validation', 'test']:\n",
    "  for label in labels:\n",
    "    df_freq = df_freq.append(\n",
    "        pd.Series(data={'Set': folder,\n",
    "                        'Label': label,\n",
    "                        'Frequency':int(len(os.listdir(my_data_dir+'/'+ folder + '/' + label)))}\n",
    "                  ),\n",
    "                  ignore_index=True\n",
    "        )\n",
    "    \n",
    "    print(f\"* {folder} - {label}: {len(os.listdir(my_data_dir+'/'+ folder + '/' + label))} images\")\n",
    "\n",
    "print(\"\\n\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(data=df_freq, x='Set', y='Frequency', hue='Label')\n",
    "plt.savefig(f'{file_path}/labels_distribution.png', bbox_inches='tight', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888ce01f-d446-4bca-a262-1aeb8a8cfc6b",
   "metadata": {},
   "source": [
    "## Image data Augmentation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea43af8-bb21-4b0e-80c0-4be6f09f3e2e",
   "metadata": {},
   "source": [
    "### Image data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dcd8c1-63e8-4bfd-8153-52137afe66e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819337fb-32ad-460c-a3ae-d8205b6bf852",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_image_data = ImageDataGenerator(rotation_range=20,\n",
    "                                          width_shift_range=0.10,\n",
    "                                          height_shift_range=0.10,\n",
    "                                          shear_range=0.1,\n",
    "                                          zoom_range=0.1,\n",
    "                                          horizontal_flip=True,\n",
    "                                          vertical_flip=True,\n",
    "                                          fill_mode='nearest',\n",
    "                                          rescale=1./255\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a60499c-02ca-4e44-9a0b-9e760ca784fc",
   "metadata": {},
   "source": [
    "### Augment training, validation and test image dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07da76d4-58fd-48d1-ae34-8b99a851ccee",
   "metadata": {},
   "source": [
    "- #### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9499e4-839c-4c9d-905d-64d294471f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20  # Set batch size\n",
    "train_set = augmented_image_data.flow_from_directory(train_path,\n",
    "                                                     target_size=image_shape[:2],\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=batch_size,\n",
    "                                                     class_mode='binary',\n",
    "                                                     shuffle=True\n",
    "                                                     )\n",
    "\n",
    "train_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cdd974-7a46-47fc-aeb4-ab20a978e434",
   "metadata": {},
   "source": [
    "- #### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc5b24f-cc96-42f9-9f79-737b6be68e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = ImageDataGenerator(rescale=1./255).flow_from_directory(val_path,\n",
    "                                                                        target_size=image_shape[:2],\n",
    "                                                                        color_mode='rgb',\n",
    "                                                                        batch_size=batch_size,\n",
    "                                                                        class_mode='binary',\n",
    "                                                                        shuffle=False\n",
    "                                                                        )\n",
    "\n",
    "validation_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bba927a-d594-402d-8e6b-376c6520a43c",
   "metadata": {},
   "source": [
    "- #### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2305851-b1bf-45b0-bfb6-bd2bbd0d17f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = ImageDataGenerator(rescale=1./255).flow_from_directory(test_path,\n",
    "                                                                  target_size=image_shape[:2],\n",
    "                                                                  color_mode='rgb',\n",
    "                                                                  batch_size=batch_size,\n",
    "                                                                  class_mode='binary',\n",
    "                                                                  shuffle=False\n",
    "                                                                  )\n",
    "\n",
    "test_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7211f452-c781-4239-b7ef-2f86f32e7d40",
   "metadata": {},
   "source": [
    "### Plot augmented images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13222f87-0c4f-4ffc-8790-92ece6ceeb85",
   "metadata": {},
   "source": [
    "- #### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace304b9-c640-4cc7-b889-a8388a00c8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    img, label = train_set.next()\n",
    "    print(img.shape)  # (1,256,256,3)\n",
    "    plt.imshow(img[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376dd29a-3918-4ec5-b8ca-45f2ef8d95c6",
   "metadata": {},
   "source": [
    "- #### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8809166-37c5-4774-b324-f2f565daa1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    img, label = validation_set.next()\n",
    "    print(img.shape)  # (1,256,256,3)\n",
    "    plt.imshow(img[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1c4e76-5b7e-4a98-b32e-684c53beb11a",
   "metadata": {},
   "source": [
    "- #### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a022db6-91a8-4488-b98a-73bfc235b4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    img, label = test_set.next()\n",
    "    print(img.shape)  # (1,256,256,3)\n",
    "    plt.imshow(img[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46295259-13cd-462e-bf96-8d80678b781d",
   "metadata": {},
   "source": [
    "#### Save class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81aeb2f-15f0-4972-947d-8133f4207ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(value=train_set.class_indices,\n",
    "            filename=f\"{file_path}/class_indices.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adb0979-1381-4cb4-a2b2-702e0053f0ea",
   "metadata": {},
   "source": [
    "## Model Creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ab639a-0188-4897-9ccb-ee9ee5430626",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5766f3d-ba69-4bcc-9a2c-4eadd48e67f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=image_shape, activation='relu', ))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(filters=16, kernel_size=(3, 3), input_shape=image_shape, activation='relu', ))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(filters=8, kernel_size=(3, 3), input_shape=image_shape, activation='relu', ))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defa2120-2bae-4e18-8a3f-9c459e932949",
   "metadata": {},
   "source": [
    "##### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dd4b46-cd17-4bf2-bfbb-3ec280d2c88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_model().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789dcee5-1cd4-4e66-a86a-d78b404f16d5",
   "metadata": {},
   "source": [
    "#### Early stopping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed464afb-7213-48fe-bc88-e2bc89fea52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0579aac-4122-4510-80b3-d87bb934460f",
   "metadata": {},
   "source": [
    "#### Fit for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8239af59-bdaa-483b-a513-6c34e662df9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.fit(train_set,\n",
    "          epochs=25,\n",
    "          steps_per_epoch=len(train_set.classes) // batch_size,\n",
    "          validation_data=validation_set,\n",
    "          callbacks=[early_stop],\n",
    "          verbose=1\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca92123-a21d-4bd4-9238-9e507d49e145",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9aee27-0d01-4d05-8540-b168a4ef4ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('outputs/v1/mildew_detector_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44924d84-498b-470d-be24-151fa84add64",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4422b2ca-ed73-4abb-9608-c9e3b81291f8",
   "metadata": {},
   "source": [
    "## Model Performance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5658c2-df0c-44b5-a0bc-a71744692f6a",
   "metadata": {},
   "source": [
    "### Model Learning Curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88f9f9b-4fe5-4856-995c-9d39cbb4ea9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = pd.DataFrame(model.history.history)\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "losses[['loss', 'val_loss']].plot(style='.-')\n",
    "plt.title(\"Loss\")\n",
    "plt.savefig(f'{file_path}/model_training_losses.png', bbox_inches='tight', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\")\n",
    "losses[['accuracy', 'val_accuracy']].plot(style='.-')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.savefig(f'{file_path}/model_training_acc.png', bbox_inches='tight', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcaf7991-28a4-44e4-96ce-b7f7bd1bbbb4",
   "metadata": {},
   "source": [
    "### Model Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66457612-c640-4c3f-b270-9777ebee5361",
   "metadata": {},
   "source": [
    "#### Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8c505f-954e-4657-bf19-1076400480be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('outputs/v1/mildew_detector_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9813c32-a2b0-47c5-97a0-e6f914a39f73",
   "metadata": {},
   "source": [
    "#### Evaluate Model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d395ecb-f3d9-44f6-803f-1441fd365ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = model.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b3c435-be6d-4a4f-a71f-9997f91da1bd",
   "metadata": {},
   "source": [
    "#### Save evaluation pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d989162-c537-4320-a9ff-8c267eee6372",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(value=evaluation,\n",
    "            filename=f\"outputs/v1/evaluation.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165f4b15-f7e7-4015-9f62-d4ec08eef9f7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431ad4d2-15ca-49dc-855a-b4f40d277c8e",
   "metadata": {},
   "source": [
    "### Create a prediction based on new data input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09179f0-b649-446e-b800-7673f170ff61",
   "metadata": {},
   "source": [
    "#### Load Image as PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e883f0bc-d9ab-4b09-b46a-6274d6cb234e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "pointer = 66\n",
    "label = labels[0]  # select Uninfected or Parasitised\n",
    "\n",
    "pil_image = image.load_img(test_path + '/' + label + '/' + os.listdir(test_path+'/' + label)[pointer],\n",
    "                           target_size=image_shape, color_mode='rgb')\n",
    "print(f'Image shape: {pil_image.size}, Image mode: {pil_image.mode}')\n",
    "pil_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdde943-3bed-4306-b2f3-a3e847b5e804",
   "metadata": {},
   "source": [
    "#### Convert image to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6faaf3-4ddd-45b7-970b-6337ab263577",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_image = image.img_to_array(pil_image)\n",
    "my_image = np.expand_dims(my_image, axis=0)/255\n",
    "print(my_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514933cc-1c40-47b1-a8cd-9e5ea7a91c6d",
   "metadata": {},
   "source": [
    "#### Class probability predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63cdf2d-ccf5-4913-8ee0-b242c197aba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba = model.predict(my_image)[0, 0]\n",
    "\n",
    "target_map = {v: k for k, v in train_set.class_indices.items()}\n",
    "pred_class = target_map[pred_proba > 0.5]\n",
    "\n",
    "if pred_class == target_map[0]: pred_proba = 1 - pred_proba\n",
    "\n",
    "print(pred_proba)\n",
    "print(pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93db5f8-4bff-40cc-8169-982cdb5cd0c4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f46c334-46b3-42c6-b35e-dd3c465df012",
   "metadata": {},
   "source": [
    "### Add, commit and push to github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc12aea-d9cf-4594-8752-3ddf0b1f665a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! git add ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd242a16-0a29-4e6a-b0e3-ec611fa606d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "! git commit -m \"create and evaluate a model which predicts a healthy or infected leaf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f39b3b-bbaf-43df-8f84-2b93fbde5f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! git push"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
